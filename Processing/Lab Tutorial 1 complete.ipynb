{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Tutorials\n",
    "\n",
    "This workbook will go over the material covered to perform analysis on the data you gathered in the wave lab. \n",
    "\n",
    "There are nearly a hundred files and many hundreds of thousands of records in the data set you collected. While this would be painful bordering on impossible in Excel, it can be done easily using a programming language. While Matlab or R are options, we will use [Python](https://www.python.org/) because it has one of the very best data analysis libraries, it is easy to use, and is open source. \n",
    "\n",
    "Programming is one of the most employable skills you can develop. If you have never done any programming before, you should start by completing a basic tutorial course. The [offshore blakboard site](https://blackboard.soton.ac.uk/webapps/blackboard/content/listContentEditable.jsp?content_id=_3963975_1&course_id=_183392_1) has a link to two such tutorials, but there are literally hundreds of other options on the web. These typically only take around 2-4 hours to complete and will make all the difference to a novice completing the lab report.\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "This document was written as a [Jupyter notebook](http://jupyter.org/). If you are using your own computer you should download and install [Anaconda](https://www.anaconda.com/download) which include Python, Jupyter and all the major Python packages. The university computers already have anaconda installed. \n",
    "\n",
    "You should also download [the lab data file](https://www.dropbox.com/s/1xvxhoi09mzd85g/wavelab2018.zip?dl=0). This has all the data from the lab groups. Copy this notebook file into the `Processing` folder of that zip file. There is already a python file called `analysis.py` in that folder. \n",
    "\n",
    "Open this notebook file with Jupyter (choose Python 3 if you are given the option) put our cursor in the following cell and run the cell either by clicking the run botton above or typing `SHIFT+RETURN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imports the functions in the `analysis.py` file. This script defines some functions to read in data and preform some standard analysis techniques (like [an FFT](https://en.wikipedia.org/wiki/Fast_Fourier_transform)). Importing it makes those functions available to use. If the code didn't work, then make sure you have this file in the same folder as the `analysis.py` file.\n",
    "\n",
    "\n",
    "## Tutorial 1: Basic data operations\n",
    "\n",
    "\n",
    "We will also import a numeric library for python `numpy`, the data analysis library `pandas`, and the plotting library `pyplot`. Again, you need to run each of these cells to get the following ones to work. You can also restart the notebook and/or run all the cells from the `Kernel` menu above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating, writting, and manipulating dataframes\n",
    "\n",
    "Let's start by creating a table of data. In Pandas, this is called a `DataFrame`. As an example let use the data collected by three of the lab groups on the properties of the mooring line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mooringlineDF = pd.DataFrame({'length':[10.,10.2,10.1],\n",
    "                              'mass':[1.15,1.17,1.12],\n",
    "                              'volume':[1e-4,1.3E-4,0.00018]})\n",
    "mooringlineDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `mooringlineDF` holds the full table of data. Writing the name by itself at the end of the cell should print the values. If not, replace that line with `print(mooringlineDF)`\n",
    "\n",
    "We can get statistics of a DataFrame easily in Pandas. For example lets use the `mean` of the measurements as our \"lab truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mooringline = mooringlineDF.mean()\n",
    "mooringline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a new \"column\" of the DataFrame using formulas or functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grav = 9.81; rho_water = 1000\n",
    "mooringline['density'] = mooringline.mass/mooringline.volume\n",
    "# g*(mass-density_water*volume)/length\n",
    "mooringline['imm_weight'] = grav*(mooringline.mass-rho_water*mooringline.volume)/mooringline.length\n",
    "mooringline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "What was the mooring line made out of?\n",
    " - Lead\n",
    " - Mild steel\n",
    " - Stainless steel\n",
    " - Aluminum\n",
    " \n",
    "---\n",
    "\n",
    "### Reading, describing and plotting data\n",
    "\n",
    "We can also read DataFrames into python use the `read_csv` function. Here is the test matrix we ran for the lab including your comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../TestMatrix.csv'\n",
    "test_matrix = pd.read_csv(filename)\n",
    "test_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### WaveProbe and Data pipelines\n",
    "\n",
    "Now lets start looking at the data. First, let's look a some data from a wave probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../WaveProbe/run2.csv'\n",
    "(pd.read_csv(filename)\n",
    " .head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head` function shows us the header and first few rows of a data frame. The wave probe csv doesn't have a header explaining what is in each column, but it recorded the date, time, wave height (in $m$) a few garbage columns, and then the speed of sound (in $m/s$). We will use the `read_waves` function defined in `analysis.py` to tidy this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(read_waves(filename)\n",
    " .head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note `time` is measured in seconds from the start of the file, and `eta1` and `eta2` are the two wave probe elevation measurements in meters. Let's plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(read_waves(filename)\n",
    " .plot(x='time'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_waves(filename).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the data is recorded for five minutes and the elevation varied from $z\\approx \\pm 0.005$ meters. The plot shows a pretty nice wave case. There is a ramp up - a constant elevation section - and then the ramp down around 120 seconds later. But then... we see the same group again (with lower amplitude) after it reflects off the \"beach\".\n",
    "\n",
    "### Quiz\n",
    "\n",
    "Which wave probe was on the carriage?\n",
    "\n",
    "- eta1\n",
    "- eta2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in on the part of the data we want by `query`ing a range of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(read_waves(filename)\n",
    " .query('time>50 & time<120')\n",
    " .plot(x='time'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I have __piped__ the results from reading directly into the query and then into the plot function. This is called a _data pipeline_, and it is the best practise for data analysis. It clearly describes all the steps that went into a result and avoids lots of intermediate data structures we don't care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
