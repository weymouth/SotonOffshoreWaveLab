{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualisys and user defined functions\n",
    "\n",
    "The goal of this tutorial is to use the wave probe and Qualisys data to demonstrate how to develop user defined functions and loops to speed up data analysis. \n",
    "\n",
    "First, let's define a python function to replicate the wave plot of the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wave(filename,start,end=1e3):\n",
    "    (read_waves(filename)\n",
    "     .query('time>@start & time<@end')\n",
    "     .plot(x='time',title=filename))\n",
    "plot_wave('../WaveProbe/run2.csv',start=100,end=110)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the function `plot_wave` which takes in three _arguments_: the `filename` as a string, and the `start` and `end` time for the plot window. This allows us to look at any file over any window of time without further copy-pasting. Play around with the argument values.\n",
    "\n",
    "The only tricky bit of code above is the `@` symbol in front of the argument names inside the query string. This lets Pandas know they are arguments.\n",
    "\n",
    "The next step is to loop over all the runs. This is done with a `for` loop and a `format` function to make each file name string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_nums = [1,2,3,4,'5_6',7,'8_9',10]\n",
    "for run in list_nums:\n",
    "    filename = '../WaveProbe/run{}.csv'.format(run)\n",
    "    plot_wave(filename,start=0,end=2e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the first run looks like somethings gone wrong and we'll have to ignore that data. There are also a few spikes which indicate momentary errors in the data aquisition. This is very typical and so we should use robust metrics like [mad](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mad.html) rather than simply min/max. \n",
    "\n",
    "---\n",
    "\n",
    "Next let's read the Qualisys data.\n",
    "\n",
    "The qualisys data recorded motion tracking data for the Dynamic Positioning (_smarty_) and moored platforms during each run. I've created a function `read_qualisys` to get that data.\n",
    "\n",
    "First let's see what the function help looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(read_qualisys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to give it a file name, but also an offset to tell the method which columns we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../Qualisys/run0002_6D.tsv'\n",
    "smarty_offset = 19  # I think this is smarty\n",
    "(read_qualisys(filename,smarty_offset)\n",
    " .plot(x='time',y='q_6'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../Qualisys/run0002_6D.tsv'\n",
    "smarty_offset = 2  # I think this is for smarty\n",
    "moored_offset = 19   # I think this is the first column for the moored platform\n",
    "read_qualisys(filename,moored_offset).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_qualisys(filename,smarty_offset).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataframe has the recorded location of each rigid body degree of freedom ($q_1\\ldots q_6$) measured at 100 $Hz$. Note that we have correctly identified smarty and the moored platform because the smarty moves around a lot more (under it's own power) in these small waves.\n",
    "\n",
    "Let's plot the heave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(read_qualisys(filename,moored_offset)\n",
    " .plot(x='time',y='q_3'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good, but the mean must have something to do with the distance blow the qualisys cameras instead of the equilibrium height. Let's write a little function to zero the mean of the heave data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mean_heave(df): # df can be _any_ data frame\n",
    "    df.q_3 = df.q_3-df.q_3.mean() # remove the mean\n",
    "    return df\n",
    "\n",
    "(read_qualisys(filename,moored_offset)\n",
    " .pipe(zero_mean_heave)\n",
    " .plot(x='time',y='q_3'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote a little function that takes the data as an input and returns the modified data. Then we included it in the pipeline with the `pipe` function. Pretty slick!\n",
    "\n",
    "How about the smarty heave?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(read_qualisys(filename,smarty_offset)\n",
    " .plot(x='time',y='q_3'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have more data aquisition problems. In this case, when Qualysis looses track of the vehicle it just returns $q=0$. But it would be much better to drop these values instead. Let's use `query` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(read_qualisys(filename,smarty_offset)\n",
    " .query('q_3!=0') # select all points with non-zero heave\n",
    " .pipe(zero_mean_heave)\n",
    " .plot(x='time',y='q_3'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better, but now there are big gaps in the signal. Alternatively, we could use the `interp_bad` function in analysis.py.\n",
    "\n",
    "For now, lets live with it and look at the horizontal plan motions for each platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(read_qualisys(filename,moored_offset)\n",
    " .query('q_2!=0')\n",
    " .plot(x='q_1',y='q_2',title='moored'))\n",
    "\n",
    "(read_qualisys(filename,smarty_offset)\n",
    " .query('q_2!=0')\n",
    " .plot(x='q_1',y='q_2',title='smarty'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in scale! Here's a version showing both on top of each other, and I've looped over all the runs in the `range` 1--11. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@try_catch\n",
    "def plot_horizontal(filename):\n",
    "    moored = read_qualisys(filename,moored_offset).query('q_2!=0')\n",
    "    smarty = read_qualisys(filename,smarty_offset).query('q_2!=0')\n",
    "    plt.plot(moored.q_1,moored.q_2,label='moored')\n",
    "    plt.plot(smarty.q_1,smarty.q_2,label='smarty')\n",
    "    plt.title(filename)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "for run in range(1,11):\n",
    "    filename = '../Qualisys/run{:04d}_6D.tsv'.format(run)\n",
    "    plot_horizontal(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the moored object stays pretty weel fixed compared to smarty. We also see that we have a small naming convention problem in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
