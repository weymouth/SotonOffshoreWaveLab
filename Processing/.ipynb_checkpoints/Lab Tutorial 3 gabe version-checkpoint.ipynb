{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from analysis import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moored_fn = '../Qualisys/run0008_0009_6D.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the displacement in the wave direction (remember this was q_3 from last week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the data and make sure it looks OK\n",
    "read_moored(moored_fn).plot(x='time',y='q_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in the data once the second set of waves arrive at the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_start(df):\n",
    "    return df-df.iloc[0] # subtract off first row values from every row\n",
    "\n",
    "(read_moored(moored_fn).\n",
    "    query('time>550').   # approximate start of second run\n",
    "    pipe(zero_start).\n",
    "    plot(x='time',y='q_3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to trim the dataset and measure time and displacement from this starting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_fn = '../MooredStrain/run8_9/strain.csv'\n",
    "list(pd.read_csv(strain_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are terrible names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_strain(filename):\n",
    "    return (pd.read_csv(filename).\n",
    "            rename(columns={\"epoch_time\": \"time\", \" strain\": \"strain\"}).\n",
    "            pipe(zero_start))\n",
    "list(read_strain(strain_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect the start of the 2nd run as for qualisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(read_strain(strain_fn).\n",
    "    query('time>350'). # approximate start of second run\n",
    "    pipe(zero_start).\n",
    "    plot(x='time',y='strain'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To synchronize datasets, first check sampling frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strain, use .diff to get the difference between consecutive values\n",
    "read_strain(strain_fn)['time'].diff().plot()\n",
    "plt.show()\n",
    "read_moored(moored_fn)['time'].diff().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_freq = 10\n",
    "\n",
    "moored_df = (read_moored(moored_fn)\n",
    "             .query('time>550')\n",
    "             .pipe(zero_start)\n",
    "             .pipe(resample_evenly,sample_freq))\n",
    "strain_df = (read_strain(strain_fn)\n",
    "             .query('time>350')\n",
    "             .pipe(zero_start)\n",
    "             .pipe(resample_evenly,sample_freq)\n",
    "             .head(len(moored_df.index)))\n",
    "\n",
    "# Check correlation\n",
    "\n",
    "plt.scatter(moored_df.q_3,strain_df.strain,c=strain_df.time)\n",
    "plt.xlabel('q_3 (m)')\n",
    "plt.ylabel('strain (V)')\n",
    "plt.colorbar(label='time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth out the voltage by running average (low pass filter) with 10s time window\n",
    "strain_df['strain_smooth'] = low_pass(strain_df.strain,dt=10,Hz=sample_freq)\n",
    "\n",
    "plt.scatter(strain_df.time, strain_df.strain, alpha = 0.1, label = 'raw')\n",
    "plt.plot(strain_df.time, strain_df.strain_smooth, label = 'low pass')\n",
    "plt.title('Low pass filter application')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('strain (V)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(moored_df.q_3,strain_df.strain_smooth,c=strain_df.time)\n",
    "plt.xlabel('q_3 (m)')\n",
    "plt.ylabel('strain (V)')\n",
    "plt.colorbar(label='time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good correlation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
